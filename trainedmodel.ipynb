{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd70c4a1-56dc-42cf-bf7d-f5b7768d3bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e2ea634-9757-48fd-8f08-397e1635c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'images/train'\n",
    "TEST_DIR = 'images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b0c1a44-b92b-47d2-84e0-e25c9393dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir,label)):\n",
    "            image_paths.append(os.path.join(dir,label,imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    return image_paths,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1881130-191b-45a8-931f-f7b1e1c4ea60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a552db7-2f43-4266-bab7-be7721dc4328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                image     label\n",
      "0            images/train\\angry\\0.jpg     angry\n",
      "1            images/train\\angry\\1.jpg     angry\n",
      "2           images/train\\angry\\10.jpg     angry\n",
      "3        images/train\\angry\\10002.jpg     angry\n",
      "4        images/train\\angry\\10016.jpg     angry\n",
      "...                               ...       ...\n",
      "28816  images/train\\surprise\\9969.jpg  surprise\n",
      "28817  images/train\\surprise\\9985.jpg  surprise\n",
      "28818  images/train\\surprise\\9990.jpg  surprise\n",
      "28819  images/train\\surprise\\9992.jpg  surprise\n",
      "28820  images/train\\surprise\\9996.jpg  surprise\n",
      "\n",
      "[28821 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d90b47bb-6fea-4a25-9b52-2350a882a4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c53e08ad-9c2a-4824-bb33-87722eb1ae7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              image     label\n",
      "0       images/test\\angry\\10052.jpg     angry\n",
      "1       images/test\\angry\\10065.jpg     angry\n",
      "2       images/test\\angry\\10079.jpg     angry\n",
      "3       images/test\\angry\\10095.jpg     angry\n",
      "4       images/test\\angry\\10121.jpg     angry\n",
      "...                             ...       ...\n",
      "7061  images/test\\surprise\\9806.jpg  surprise\n",
      "7062  images/test\\surprise\\9830.jpg  surprise\n",
      "7063  images/test\\surprise\\9853.jpg  surprise\n",
      "7064  images/test\\surprise\\9878.jpg  surprise\n",
      "7065   images/test\\surprise\\993.jpg  surprise\n",
      "\n",
      "[7066 rows x 2 columns]\n",
      "0         images/test\\angry\\10052.jpg\n",
      "1         images/test\\angry\\10065.jpg\n",
      "2         images/test\\angry\\10079.jpg\n",
      "3         images/test\\angry\\10095.jpg\n",
      "4         images/test\\angry\\10121.jpg\n",
      "                    ...              \n",
      "7061    images/test\\surprise\\9806.jpg\n",
      "7062    images/test\\surprise\\9830.jpg\n",
      "7063    images/test\\surprise\\9853.jpg\n",
      "7064    images/test\\surprise\\9878.jpg\n",
      "7065     images/test\\surprise\\993.jpg\n",
      "Name: image, Length: 7066, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test)\n",
    "print(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eea6ed88-eebb-4a1a-9ecd-bafd472d484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a4b042f-ba19-4f0b-81f3-3d6440b0b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image,grayscale =  True )\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features),48,48,1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1169d41f-c07c-420a-b3a6-4565525bcc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28821/28821 [00:08<00:00, 3266.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Features Shape: (28821, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # Ensure tqdm is imported\n",
    "\n",
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image_path in tqdm(images):\n",
    "        try:\n",
    "            img = load_img(image_path, color_mode='grayscale')  # Load image in grayscale\n",
    "            img_array = img_to_array(img)  # Convert to NumPy array\n",
    "            img_array = img_array / 255.0  # Normalize pixel values (optional but recommended)\n",
    "            features.append(img_array)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")  # Print errors instead of silent failure\n",
    "    return np.array(features)\n",
    "\n",
    "# Example Usage:\n",
    "# Assuming 'train' is a DataFrame and 'image' column contains image file paths.\n",
    "train_features = extract_features(train['image'].tolist())  \n",
    "print(f\"Extracted Features Shape: {train_features.shape}\")  # To check output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bc37a82-dd8f-4bd9-af76-f55203136627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7066/7066 [00:02<00:00, 3202.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Test Features Shape: (7066, 48, 48, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image_path in tqdm(images):\n",
    "        try:\n",
    "            img = load_img(image_path, color_mode='grayscale')  # Load image in grayscale\n",
    "            img_array = img_to_array(img)  # Convert to NumPy array\n",
    "            img_array = img_array / 255.0  # Normalize pixel values\n",
    "            features.append(img_array)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")  # Print errors instead of failing\n",
    "    return np.array(features)\n",
    "\n",
    "# **Extract Test Features**\n",
    "test_features = extract_features(test['image'].tolist())  \n",
    "print(f\"Extracted Test Features Shape: {test_features.shape}\")  # To check output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1e2f81c-4dd5-44e7-9f3b-41aa8dd8e536",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24b92825-bff9-4174-9e02-9bf61cefec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f953649-580a-4e72-a024-ce05fb710cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LabelEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49379b8c-488f-436c-b402-8b7e2f67b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c9395a0-ceee-4a3d-9800-4fb92ad23180",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes = 7)\n",
    "y_test = to_categorical(y_test,num_classes = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0f24037-22dc-41e9-baca-7090061cb609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m1,280\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m262,656\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │           \u001b[38;5;34m1,799\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,232,199</span> (16.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,232,199\u001b[0m (16.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,232,199</span> (16.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,232,199\u001b[0m (16.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Input\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Input(shape=(48, 48, 1)),  # Correct way to define input shape\n",
    "\n",
    "    # Convolutional layers\n",
    "    Conv2D(128, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Conv2D(256, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Conv2D(512, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Conv2D(512, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    # Fully connected layers\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Output layer (7 classes for emotions)\n",
    "    Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51650a1c-221e-4d43-bd82-7591e65e1f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])  # Corrected: Metrics should be inside a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d65ab77-3cd7-4463-a33c-f2a6678ec6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m 51/226\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 615ms/step - accuracy: 0.2389 - loss: 1.8640"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39m x_train,y \u001b[38;5;241m=\u001b[39m y_train, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, validation_data \u001b[38;5;241m=\u001b[39m (x_test,y_test))\n",
      "File \u001b[1;32mC:\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mC:\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mC:\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mC:\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mC:\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mC:\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mC:\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1684\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1685\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1686\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1687\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1688\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1689\u001b[0m   )\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mC:\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x= x_train,y = y_train, batch_size = 128, epochs = 100, validation_data = (x_test,y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a54138a3-0897-4cd5-818e-1a3593644549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model structure as JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Save model in the recommended `.keras` format\n",
    "model.save(\"emotiondetector.keras\")  # New format (recommended)\n",
    "\n",
    "# If you still want to save as HDF5 (legacy format), use:\n",
    "# model.save(\"emotiondetector.h5\", save_format=\"h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ab7109d-b82a-4e95-97fc-1264d9c0c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22f61f32-c2f8-4a26-8470-32ea32c07a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from JSON + HDF5!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json, Sequential\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "json_path = \"facialemotionmodel.json\"\n",
    "weights_path = \"facialemotionmodel.h5\"\n",
    "\n",
    "if os.path.exists(json_path) and os.path.exists(weights_path):\n",
    "    try:\n",
    "        # Read and load the model structure from JSON\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "            model_json = json_file.read()\n",
    "\n",
    "        # Register Sequential explicitly\n",
    "        from tensorflow.keras.saving import register_keras_serializable\n",
    "\n",
    "        @register_keras_serializable()\n",
    "        class MySequential(Sequential):\n",
    "            pass\n",
    "\n",
    "        model = model_from_json(model_json, custom_objects={\"Sequential\": MySequential})  # Load with fix\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "        print(\"Model loaded successfully from JSON + HDF5!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the model: {e}\")\n",
    "else:\n",
    "    print(\"Error: Model file not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cef7e9e6-61df-4449-acd0-e4052837ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['angry','disgust','fear','happy','neutral','sad','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9e83e0d-cdca-4bae-98db-55bd8d3aac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ef(image):\n",
    "    img = load_img(image,grayscale =  True )\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1,48,48,1)\n",
    "    return feature/255.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3e9c369-d453-4cec-bc6a-90d5400dd5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image is of sad\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "Model prediction is: neutral\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "# Define function to preprocess the image\n",
    "def ef(image):\n",
    "    img = load_img(image, color_mode='grayscale')  # Corrected argument\n",
    "    img = img_to_array(img)  # Convert image to NumPy array\n",
    "    img = img / 255.0  # Normalize pixel values (optional but recommended)\n",
    "    img = img.reshape(1, 48, 48, 1)  # Reshape to match model input\n",
    "    return img\n",
    "\n",
    "# Example Usage:\n",
    "image_path = 'images/test/sad/20.jpg'\n",
    "print(\"Original image is of sad\")\n",
    "\n",
    "# Preprocess Image\n",
    "img = ef(image_path)\n",
    "\n",
    "# Ensure `model` and `label` are defined before using them\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]  # Ensure `label` is a valid list/dictionary\n",
    "print(\"Model prediction is:\", pred_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37a4fc70-64da-455d-bf53-f86d13a089ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d12706f-e10d-4f6b-bfb1-a45371ba80d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image is of sad\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Model prediction is: sad\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAe1UlEQVR4nO3d3Wuld9XG8VVfkkmy87IzySR7Ms2M1KFqK+IbyDBSRIsgiKXgiYf+Jx7WI/8BBYVCETwUdQ6KUpTBl5Eyjq0OzBhnNNOY5j07L9NaT55nMSe/67rJmlCfh+/ndOW3973v+95ZbLjW737ivffeey8AAIiID7zfBwAA+O9BUwAAJJoCACDRFAAAiaYAAEg0BQBAoikAABJNAQCQPtT1D3/wgx/I+oc//OFm7YknnpBr33nnHVn/97//Lesf+EC7t6laRISb3fvgBz944td2n7viNN/brVXX2q131/Lhw4ey7q6Xqh8dHcm17j589913m7Xj42O5dn9/X9Yr58W993A4lPXbt283a3fu3JFr1TmJiFhbW2vWpqen5drK9YjQ31332r1eT9YPDg6atc3NTbn2Qx/S/3bdPb60tNSsnTlzRq794x//KOsR/FIAADyCpgAASDQFAECiKQAAEk0BAJBoCgCARFMAAKTOcwouF1/hcvGVzH31GUIuP66onHSE/lzVc1Kpuxy1e211zipzIV3Wq/d297B778p3wN1HLnOvrkn1u3n58uVmzc1XqLy+q7s8/2AwkPXKsbk8vzM2NtasubmRjY0NWR8fH5d19blHR0fl2i74pQAASDQFAECiKQAAEk0BAJBoCgCARFMAAKTOkdTTjCG6OJ5br47NxfUqW2tXtnHu8t6V13YqcVinemyV11Z197lO8z4bGRmRdbeVs4qkus/ljk1thf7MM8/Itbdu3ZL1ubm5Zs1FSl10c2pqSta3traaNXet3fWanZ1t1tbX1+Vad9wuvqy2QnfbkXfBLwUAQKIpAAASTQEAkGgKAIBEUwAAJJoCACDRFAAAqfOcgsvOVvL8TiXPf5qZe3dOKttXn+ZW5Y77XJXZj8q8S4TP86vr5Y67kvd3r+22Iz/NLdrdex8dHTVrMzMzcu2FCxdO/N4qbx8RsbKyIutqviIiotfrNWvb29tyrdtaW7324uKiXOs+l7sP1VyXm+3ogl8KAIBEUwAAJJoCACDRFAAAiaYAAEg0BQBAoikAAFLnOYVKPtw5zUz+aWbundPc+/8069Vzpl7bZepd3Z1TdZ+6czI6OirrlbmSypyPq1e/m2NjY82ae+bBYDCQdXU93TnZ29uTdTdrsLCw0KwdHBzItWp2I0LPWFy6dEmuvXv3rqy7uRJ1r7lz1gW/FAAAiaYAAEg0BQBAoikAABJNAQCQaAoAgERTAACkznMKlRy22v+7S91RWeiRkRG51mWC3Z7tisuHq9x7ZW//Lu9d2b/fXa/KzIo73+56qfd2x+1mJCrP5nCzBO4+VdfLne/TnMVx51Q9W6Dy3ICIiNdff13W1SyBm0lx8xmrq6vNmptT6Pf7sr61tSXr6jtSfX5MBL8UAACPoCkAABJNAQCQaAoAgERTAAAkmgIAIHWOpLq4noq1uZhUdVthFVN0EUYXBTzNSGo1inta7+3OmbueKn5ZielG1KK01Riv4r4fjjvn6py6z+WO7fDw8MTHdebMGVlX13NmZkau/ehHPyrrbpvolZWVZs1FUt13U8VGHz58KNcuLS3J+oMHD2RdnVP3ubrglwIAINEUAACJpgAASDQFAECiKQAAEk0BAJBoCgCA1HlO4ejoSL+QyDO7nHQ1461yuy57fnx8LOvqc1W2HI6oHXfltV3dXQ+XXVezBG7OwOXDK3MK1a2x1TWpnO8Ify+p9dX5C5Vtd1t+u1y8ul7uPur1erJ+5coVWVd5//HxcbnWbZ2tZjvu3r0r1z733HOyfvPmTVmvPKagC34pAAASTQEAkGgKAIBEUwAAJJoCACDRFAAAiaYAAEid5xRcPlzlmV1G2+3J7rK3KjPs5ivefvttWZ+YmGjW+v2+XDs1NSXrY2NjzZrL1LvseWXO4TTnL6qzApU8f+W5HO693T1a/dxqj/7KMz8i9LG5c+Y+13A4bNbc98OZnJyUdfU8hj//+c9yrZuRUPfC2tqaXKu+9xH+c6n/d5U5nv/FLwUAQKIpAAASTQEAkGgKAIBEUwAAJJoCACB1jqQeHBzIeiVeqSJWET5yp7bvdZG6+fl5Wd/c3GzWbt++LdeqGGFExLlz55q1wWAg17rYmov5ui2P/1u5rZzVveYip66uuKisO25HbfXs4rCVrc7dWhU5jdDH7b4fe3t7sr6zsyPrH/vYx5q1P/zhD3Kti42qqLv7f/bjH/9Y1t223SomX73PIvilAAB4BE0BAJBoCgCARFMAACSaAgAg0RQAAImmAABInYPZLod9fHzcrLlMfGU75AidpXY565GREVmfm5tr1lw+3GW4t7a2mjU3A+Hee2ZmRtZV1nlhYeHEax13ravbdqs5BTfvUrkP3X3mZnVcvlwdu8u1V865++657a83NjaaNZfnd+dUzRBFRCwuLjZrS0tLcq2bgVDzT9V7fHl5Wdb/+c9/NmtPPfWUXNsFvxQAAImmAABINAUAQKIpAAASTQEAkGgKAIBEUwAApM5zCi5TrHLWLoPt8shqBiJCPzvA5cNdDlvlkd1aNyswOzvbrLnsucto7+7uyvq9e/eatQcPHsi17nOp7LrLtbvnRLhzru4VN9vh5hjUfeqOy9Vddl29t9v73722ep6Cm7Vx10vdh+55Cu7/gntmiLqen/70p+XaX/7yl7KunsPinj3j/h9evnxZ1tWcgptx6IJfCgCARFMAACSaAgAg0RQAAImmAABINAUAQOocSe31erKuIpR7e3tyrdta2723iiGquF2Ej7WpKKGKq0b4aJqKCrrXdufERT/PnTvXrLk4q4sIr6+vN2vunBwdHcl6ZRt2d60r0WcXn6xETiNq0WgXxVV1d77d92swGDRr7h53MXgXaf3973/frK2ursq1Fy9elHW17b07LvfddVvXq7r7fnXBLwUAQKIpAAASTQEAkGgKAIBEUwAAJJoCACDRFAAAqfOcwsTEhKyrzLHLh7s8stoqNiJifHy8WXPbPO/s7Mi6ype7bLnbtlu9dnWrZZcfV1nq6enpE6+N0Ll3l013cwqVLardlsVu62xVd9fD1StbvFfPaWXb++3tbVlXn3ttbU2uXVlZKb23mjt5/vnn5Vr3ua9du9asuf8Lc3Nzsu7uBfX/1G173wW/FAAAiaYAAEg0BQBAoikAABJNAQCQaAoAgERTAACkznMKLsPd7/ebNbefe+W5AxE6z+yyzk899ZSsq8ywmwVwx632qh8ZGZFrXTbdUe/tnn/h5hQUd9zumQbO2NhYs+by35VZAcfdK66uZnHc8y/c9VR5f3c93KyAmkFy80nqmR8REc8++6ysLy0tNWvu/9ns7Kysq+vx2muvybXf/OY3Zf0nP/mJrP/tb39r1l588UW5tgt+KQAAEk0BAJBoCgCARFMAACSaAgAg0RQAAImmAABInecUXG5ezSK4TLDLaDsqU/zGG2/Itb/5zW9k/cqVK82ae8aEy7WrDLib7VBzBhF+T3f1+i6vv7GxIetK5bkcEX6mRa2vziGo+7Q6A+Go915dXZVr3fNI1OdWefwI/7wSdb3d/xR3Pdz/FTVP42Y35ufnZf3rX/96s3b16lW59s6dO7LuPvf3vve9Zu1b3/qWXNsFvxQAAImmAABINAUAQKIpAAASTQEAkGgKAIDUOZLqYqNnzpxp1ipbDneh3nthYUGuVdvQRkRcu3atWXPbbi8vL8u62tp3ampKrnXbcrvr9eDBg2bt5z//uVzrYqMqxuuism5bbve5VczXvbY7NnVOq/e4i2eqLeBv3Lgh17pjm5yclHXFXQ8VIT46OpJr3XG567W2ttasqe9ehL9XVFTXxXjd9XjppZdkXW0ZXt1SP4JfCgCAR9AUAACJpgAASDQFAECiKQAAEk0BAJBoCgCA1HlOweWRFbdtsNtO2W2Re3h42Ky5LXJdpng4HDZrP/vZz+Tafr8v62qGYjAYyLXT09Oy7uYU1Pa9au4jImJubk7WVQ77nXfekWvVtexCZdf39/flWnefqfvYzRk47r3VFu9/+ctf5FqX91fzNm7Ox313x8bGmjV3zty98te//lXWL1261Ky57727Hu7YlK9+9auy7maU1HfbzVe473YEvxQAAI+gKQAAEk0BAJBoCgCARFMAACSaAgAg0RQAAKnznILapz5C53qre833ej1ZV9lbt+f6xsaGrKv94C9evCjXusy9mqFYXV2Va9fX12Xd7VV//vz5Zs09B+Ls2bOyrrj93t08jMthq8+tMvNd3lvdSy637nLxbp7m6aefPvF7u3v8d7/7XbPm7sMnn3xS1hcXF5s1dy/8+te/lvUvfvGLsu6emaC4OQV1r5w7d06uPc3ny3SZQ3D4pQAASDQFAECiKQAAEk0BAJBoCgCARFMAAKTOkVQXH3v33Xfbb2JioW4LXRfhGh0dbdZcZM5Fz+7fv9+svfXWW3KtixmqeKWLR7qtsWdmZmRdRddc5NSdM3WvVLZgj/CfW92H7j5yW7yrz+3ucXfOHLVFtdu+2n1uFdW9ffu2XHv37l1ZV/fZ9va2XPupT31K1j/ykY/Iuoonu3tc/U+J0DFgdy+4uqPuU/f96PL945cCACDRFAAAiaYAAEg0BQBAoikAABJNAQCQaAoAgFQLzD5CZe7djIPLcFcy4G67ZJfhVnlmt534/v6+rKtz5o7LbY3tsusqz1/N1KsctdqKPMJ/bncvufOiuDkFlV13szYuP+7Wq/vw4x//uFz7j3/8Q9bVPI26TyL8d0Cd0/n5ebn2k5/8pKzPzs7KemUewG1Bre5jdy2rcwpKdQ4ogl8KAIBH0BQAAImmAABINAUAQKIpAAASTQEAkGgKAIDUOTA7HA5lfXp6ullzuV2XD3dZaZXNdbldN8egMsUuy1yZkXCf2VH7vUf4vH9lrcrkuzkCdy+o2Y6IiPHx8WbNzV9UnqfgrrWbU3DnZXJysllzsx1zc3Oyvru726y5WQFHfUfcd/P8+fOyXvnuuucluPtMzXYsLCzItTs7O7Lu1ivuu+nulQh+KQAAHkFTAAAkmgIAINEUAACJpgAASDQFAECiKQAAUuc5BZfhVrl4t4e+m2NwdZXNdflwl1dWWerDw8PSa6vz4jLYbg6hcs4qzySI0Blvt5e8+9yOul7V53ao6+2y5e56uXtJ6ff7su6eedDr9Zo1d9xqLiRCP9fDZebdd9ddL1V3/8/cXJa6T6vPj6nMAfE8BQDAY0VTAAAkmgIAINEUAACJpgAASDQFAEDqHEldXV2VdbXNrYuOudibi1mputuC2sW/VN3F2tznVnE+d9zutd16FTt1r+2igpW4q7vWKuIYoe+l6nbJ6r1d7NNFbVUsNEJvt+yinS42qrg4ufsOqPPitp5318tFOxV3j7v7VMWA3Tlx18utfxyxU/n6p/rqAID/U2gKAIBEUwAAJJoCACDRFAAAiaYAAEg0BQBA6jynsLu7K+sqj+wy2i4TXJlzcFtIuxmJCjcD4WYJKlyWWWXX3fXY29uTdXVOq9sluwy3Wu/Ot3vtysyKuxfcLIGaoajOfqhjd2vd51KzCO4zu3vBcf83FDefoeayHDdfcdpzCA6/FAAAiaYAAEg0BQBAoikAABJNAQCQaAoAgERTAACkzkHeK1euyPqrr77arF29elWudbMCh4eHsq72uR8Oh3Kt29NdZbhd5t7VlWpW2eXHVQbcra3OGlRe26nssV/J5Ls5BcedM5W5d8+BcOdUzW+48+mOu/KsEzdnUPmOuP8Lbr6pep8q1Xupil8KAIBEUwAAJJoCACDRFAAAiaYAAEg0BQBA6hxJ/dznPifrv/3tb5u1lZUVufbixYuy7iJ3aptbFzl1r61iiC4S5+oq1lbdNvg0I6nu2Cpbgrv3dvFlFaGsxnzV53IRRRczdPehime66Ob7GRFW7+2uRzUOq87L2tqaXOu2+1ev7c5ZdUt9dS+51+7yHeCXAgAg0RQAAImmAABINAUAQKIpAAASTQEAkGgKAIDUeU7BbSX7ta99rVl7+eWX5dp+vy/ramvsCJ1dd/lvlx+vZNvdWvXe1Uy9y/NXtoE+Pj6WdXXOXba8ej0qeX5HHbvLlo+Ojsq6+9xq+3i31mXXT2utW++Ou7pFu1q/ubkp17r/Oeq1K/NJVdX/GxH8UgAAPIKmAABINAUAQKIpAAASTQEAkGgKAIBEUwAApM7B7eFwKOvPPvtss/aJT3xCrn3zzTdl3T3LQWXyXX681+vJeuXZAE5lTqF6XCor7a71W2+9JevqerjP5Z5/4eZl1Odycwquro7dzW64/fndeVFzCu65Ay4XX7lelbkSd87ccbt7YX19vVlz19rdh+rYqs/WOM05hi74pQAASDQFAECiKQAAEk0BAJBoCgCARFMAACSaAgAgdZ5TcNlZlaN+/vnn5dof/ehHsq7yxhERZ8+ebdZcztplpVWe2Z0Ttxe92w9ecc9LcHX1zIPt7W25dm9vT9ZVxtudM/f8i8rzGFw23eX91WtXzncX+/v7zdr4+Lhce5r7+1eet3B0dCTr7hkUzv3795u1xcVFudbNlVTOmVtb+b/irkeX5y3wSwEAkGgKAIBEUwAAJJoCACDRFAAAiaYAAEidI6mOinb2+3259urVq7J+/fp1WZ+enm7W3Pa6LipYiaQ6avvr6tbYbr2KA25sbJReW0VS3fVwEeFKtNPF9U5zy2L3uVz8Un1uF+1020CrmKI7324baMXFi931cFu4q9d38ePKvVKJmrvX7lKv4pcCACDRFAAAiaYAAEg0BQBAoikAABJNAQCQaAoAgNR5TsHllVUWWm2rHRGxvLws67du3ZJ1laufn5+Xa10eWW2J7LLOLq+s8v5ui1tXd1s5q2vicu/uvdUswuTkpFzr7rPhcCjr6j6sXA+33mXH3Wt32dK4xZ0zNxuijt3NV0xMTMh65Zy5e3hlZUXWB4OBrFeo+aXK/5SI2vbwjwO/FAAAiaYAAEg0BQBAoikAABJNAQCQaAoAgERTAACkznMKLmetstIuz+9y1JcvX5b1mzdvNmunOafg8uEuh60+t8squ6yz+1xqTqGag1azCCrf3aXuzqn63G4WwL22mt9w93B1rqQyB+S+u+qcu3uh8tyPqakpWb9x40bpvcfHx5u1sbExudZdz8r8hftuu++uqj+OZy3wSwEAkGgKAIBEUwAAJJoCACDRFAAAiaYAAEidI6kuRuXqitue98knn5T1u3fvnvi1VdQvQse/qlsxv59bZ6v3Hh0dPfHaiIj79+83ay4K6CKpKmYYoc+Li1fu7e3J+szMTLPmtht3MUNHxbrdta5s8V7dElxFOx88eCDXui3zP/vZz8q6Uv1+KdXIaSVW+jhem18KAIBEUwAAJJoCACDRFAAAiaYAAEg0BQBAoikAANJj2zpbcTlqlwl2W+yeP3++Wbt3755cu7S0JOsq91vZkthxeWJ3Tl1dZfbdLID7XOvr683a5uamXOvO6dzcnKyrY3MzEr1eT9bVNXGvPT09LevD4VDW1eu7+Ytqbr5CzQH96le/kmsvXrwo64PBQNbVveDuYfc/qfJ/oUrdh4/jWvJLAQCQaAoAgERTAAAkmgIAINEUAACJpgAASDQFAEDqHKR3+df389kAy8vLzdrt27flWpcpVp/bPYvBZaEfPnzYrLnP7OYYKnllt9ZdLzVLsL+/L9e6zzU5OSnrKpM/MTEh17rnDqhZAjcr4OYY3OeuZO7dsalnQbhnTLjvwOuvv96suXvhM5/5jKy7eRr1XJDKDFFE7Tkr1e9u5fkXXfBLAQCQaAoAgERTAAAkmgIAINEUAACJpgAASJ1zWZWtnF1srRJ3jYiYmZlp1s6ePSvXulicikAeHBzItZWttV1krhJbi4gYGRlp1lw0c2dnR9ZVZNXdC+q4InTMMELHL12c1cVG1X3mzln1Hlef211rFX2O0MfmrsfW1pasX79+vVm7evWqXOuutaPuQ3e9KrFRt9ZFuisx+WrUNoJfCgCAR9AUAACJpgAASDQFAECiKQAAEk0BAJBoCgCAVA+1/g+VD3fbQFcz+Sr3e+HCBbn2zTfflPWpqalmzeWJXT5cHbdbe3x8LOvu2FSW2q11eX51vd1aN8fgsuvqc7n7qPLa1e3hXba9sl2y+36p6+1mIH7605/K+tNPP92sVedGXL0yB+SuV2VrereVuaOuiTuuLltr80sBAJBoCgCARFMAACSaAgAg0RQAAImmAABINAUAQOo8p+Dyyip763LvLpvu3lu9/tzcnFzrcrvqmQkuJ+0cHR01a+6cuRy1y2EPh8NmzZ0Ttxe9O3bF3QuVGQl1viP8OVXcPeq4WR51zt35djMt6rt77do1udY9b2EwGDRr7lq7PL87571e78SvXXmeQmWuKqL2uav/NyL4pQAAeARNAQCQaAoAgERTAAAkmgIAINEUAACJpgAASJ3nFFz+VWVnXa7dZYJdnnlnZ6dZc3u2u/ru7u6J3jfCzwrMzs42ay7/7bhnA7hjU1zuXV2vSq49wmfA19fXmzV3H7p8uJqRcM+/cHMIlecpuPkLd86vX7/erN27d0+ufe6552R9fHy8WZuYmJBr3XFX5puqzzSocO/t6pUZiS74pQAASDQFAECiKQAAEk0BAJBoCgCARFMAAKTOuUQXqVORVRcFdNx6FU1zUcH5+XlZX1lZOfFr//3vf5f1mzdvNmv9fl+udZHSSvzSRQWnp6dlXR2bi7P+61//kvULFy7Iuoq0uvd22wqruJ+LR7rvj9sG+v79+82a2iI6IuJPf/qTrL/66qvN2pe+9CW5dmZmRtZVrNSds8pW5m69ux4u0q3uBRcvdt9d939Ffa69vT25tkvUnV8KAIBEUwAAJJoCACDRFAAAiaYAAEg0BQBAoikAAFLnOQWXrVW5XZcJdnlkl7lXOW23rbDL3Kts+9mzZ+XahYUFWV9bW2vWVC7dHVeEv15bW1vNmtouPCLi4OBA1tV5cefEXevl5WVZX1xcbNYODw/lWnevqM/tcu1zc3Oy7ramV69/48YNufaHP/yhrL/wwgvNmtrePcJfL1WvbmXu5gHU/xW31s0KqOtV3bbefbe3t7ebNbW9e1f8UgAAJJoCACDRFAAAiaYAAEg0BQBAoikAABJNAQCQOs8p7OzsyLrK+7vcrptTcBlulTl2Wedz587Jusr9uiyzy2Grvf/dPvVu9sPtm67Oi3vtjY2NE9fVbEZExNtvvy3rd+7ckXU1x+Ay95VnA7h73N0LS0tLsn7r1q1m7aWXXpJrv/GNb8j6pUuXmrXx8XG51n0utd7do+7/gqurZ1RU/+eo9e7/gptDcHNAas6hy/MSHH4pAAASTQEAkGgKAIBEUwAAJJoCACDRFAAAqXMkVW2NHaFjWC7eVYmcRuhYnFvb7/dlXUW81Ba2ET72pmKMLuLoYm/r6+uyro7NRTMvX74s6yr66e4jF8dzcVl1PSvbv0forbfd2qmpKVl3Ud3vfOc7zdrnP/95ufYLX/iCrE9MTDRr7py5+1RFut33w3HfbXVN3PWqcDF4F0l1VPzffT+64JcCACDRFAAAiaYAAEg0BQBAoikAABJNAQCQaAoAgNR5TsHlX1WG+8yZM3Kty/W6rLTi8sjutefn55u1lZUVudbNQKhjOzo6kmtdRtvlx4fDYbO2ubkp17pzpu4Vd9xu61+1HXJExO7ubrPm7jN3j6v3dnMIbv7iu9/9rqxPTk42a1/5ylfkWjcPoL6fas4gwm+tre4V991018vV3b1Woe4V971395k7bjWj5OaXuvwv5ZcCACDRFAAAiaYAAEg0BQBAoikAABJNAQCQaAoAgNR5AKCS8a5m7l22Vh2be21XX15ebtauX78u17o8ssqHu/Pt8vxuTkF9bpcfd3MM6nqrvfsj9PxEhH/2hrpX3FqXL1eZfDcL8P3vf1/W33jjDVn/9re/3ay5e8HNUKjnkbjXVmsj9H3mvnvVOQQ301J5bXVe3PfefS53n+7v7zdr1WdURPBLAQDwCJoCACDRFAAAiaYAAEg0BQBAoikAABJNAQCQOs8pDAYDWVf5cpf5Vc9iiPBZaJXNdTMOLpOvcvUu/+1y0mqPfTdnUJ1jqDyjwu3ZruYU1PMOIvxxuRy2qrs5BHfO1VzJa6+9Jtf+4he/kPUvf/nLsj47O9uszczMyLXunKlz7r577j5Uqs87cHl+dWzVZ7ioe8XN2rjvpvt/WPlcXfBLAQCQaAoAgERTAAAkmgIAINEUAACJpgAASJ1ziS5Gpeou1ra9vS3rx8fHsq4ikipGGOFjcWq92kq5i7GxsRO9bxcuUqeul4vSuujm9PS0rCtu22F3zivxZHefbmxsNGuvvPKKXPvMM8/I+qVLl2R9cnKyWXMxRPe51H3ovvePIwLZUtn6OkJ/h9RnrnL3mYvSurq6F1zEvgt+KQAAEk0BAJBoCgCARFMAACSaAgAg0RQAAImmAABIT7z3OIKtAID/F/ilAABINAUAQKIpAAASTQEAkGgKAIBEUwAAJJoCACDRFAAAiaYAAEj/AQl3yzbLsPR3AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Function to preprocess the image\n",
    "def ef(image_path):\n",
    "    img = load_img(image_path, color_mode='grayscale')  # Load in grayscale\n",
    "    img_array = img_to_array(img)  # Convert image to array\n",
    "    img_array = img_array / 255.0  # Normalize pixel values\n",
    "    img_array = img_array.reshape(1, 48, 48, 1)  # Reshape for model input\n",
    "    return img_array, img  # Return both processed image and original image\n",
    "\n",
    "# Image path\n",
    "image_path = 'images/train/sad/42.jpg'\n",
    "\n",
    "# Display original image\n",
    "print(\"Original image is of sad\")\n",
    "img_processed, img_original = ef(image_path)\n",
    "\n",
    "# Model Prediction\n",
    "pred = model.predict(img_processed)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"Model prediction is:\", pred_label)\n",
    "\n",
    "# Display Image\n",
    "plt.imshow(np.array(img_original).reshape(48, 48), cmap='gray')  # Use original image\n",
    "plt.axis(\"off\")  # Hide axis\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dda188f2-a884-4e92-9092-659503784bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image is of fear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Model prediction is: sad\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "# Function to preprocess the image\n",
    "def ef(image_path):\n",
    "    img = load_img(image_path, color_mode='grayscale')  # Load image in grayscale\n",
    "    img_array = img_to_array(img)  # Convert to NumPy array\n",
    "    img_array = img_array / 255.0  # Normalize pixel values\n",
    "    img_array = img_array.reshape(1, 48, 48, 1)  # Reshape for model input\n",
    "    return img_array, img  # Return processed & original image\n",
    "\n",
    "# Image path\n",
    "image_path = 'images/train/fear/2.jpg'\n",
    "print(\"Original image is of fear\")\n",
    "\n",
    "# Preprocess image\n",
    "img_processed, img_original = ef(image_path)\n",
    "\n",
    "# Model Prediction\n",
    "pred = model.predict(img_processed)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"Model prediction is:\", pred_label)\n",
    "\n",
    "# Display Image\n",
    "plt.imshow(np.array(img_original).reshape(48, 48), cmap='gray')  # Use original image\n",
    "plt.axis(\"off\")  # Hide axis\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf34a345-2b81-41e1-ae6c-62ccf033b3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
